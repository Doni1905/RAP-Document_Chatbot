# ğŸ¤– RAG Chat Assistant

A modern, fully offline Retrieval-Augmented Generation (RAG) chatbot that transforms your documents into intelligent conversations. Built with a beautiful, responsive UI and powered by open-source models and tools.

---

## ğŸ‘¥ Authors

- **Doneeswaran**
- **Rashmi**

---

![RAG Chat Assistant](https://img.shields.io/badge/Status-Active-brightgreen)
![Python](https://img.shields.io/badge/Python-3.10+-blue)
![Streamlit](https://img.shields.io/badge/UI-Streamlit-red)
![Qdrant](https://img.shields.io/badge/VectorDB-Qdrant-green)
![Ollama](https://img.shields.io/badge/LLM-Ollama-orange)

---

## âœ¨ Features

### ğŸ¨ **Modern UI/UX**
- **Beautiful Intro Page**: Eye-catching landing page with feature highlights
- **Responsive Design**: Works perfectly on desktop, tablet, and mobile
- **Theme Support**: Light and dark mode with smooth transitions
- **Enhanced Sidebar**: Professional gradient headers and organized sections
- **Real-time Status**: Live monitoring of Qdrant and Ollama services

### ğŸ“š **Document Processing**
- **Multiple Formats**: Support for PDF, TXT, and DOCX files
- **Smart Chunking**: Intelligent document segmentation with context preservation
- **Instant Processing**: Fast document ingestion and indexing
- **Batch Upload**: Upload multiple documents simultaneously

### ğŸ§  **AI-Powered Chat**
- **Context-Aware**: Answers based on your uploaded documents
- **Source Citations**: Shows which documents and pages were used
- **Intelligent Retrieval**: Finds the most relevant information
- **Natural Conversations**: Human-like responses powered by Ollama LLMs

### âš¡ **Performance & Reliability**
- **Offline-First**: Works completely offline after initial setup
- **Fast Retrieval**: Optimized vector search with Qdrant
- **Memory Efficient**: Smart resource management
- **Scalable**: Handles large document collections

---

## ğŸ“¸ Output Screenshots & Results

All project outputs, screenshots, and sample results are available at the following Google Drive link:

[ğŸ‘‰ View Project Outputs on Google Drive](https://drive.google.com/drive/folders/1twm6pmxXxTxemngfj8DpL6KdcFEJHEH3)

---

## ğŸ”— Project Output Drive Link

All project outputs, including screenshots, sample runs, and documentation, are available at:

[Google Drive Output Folder](https://drive.google.com/your-output-link)

---

## ğŸš€ Quick Start

### 1. Clone & Setup
```bash
git clone https://github.com/Doni1905/RAP-Document_Chatbot.git
cd RAP-Document_Chatbot
```

### 2. Install Dependencies
```bash
# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 3. Start Services
```bash
# Start Qdrant (Vector Database)
docker start qdrant_rag || docker run -d --name qdrant_rag -p 6333:6333 -v $(pwd)/docs_index:/qdrant/storage qdrant/qdrant

# Start Ollama (LLM Server)
ollama serve
ollama pull mistral  # or phi3, llama3, etc.
```

### 4. Launch the App
```bash
streamlit run app.py
```

Open [http://localhost:8501](http://localhost:8501) in your browser and start chatting! ğŸ‰

---

## ğŸ’¬ How to Use

### ğŸ“– **Getting Started**
1. **Welcome Screen**: Enjoy the beautiful intro page showcasing key features
2. **Upload Documents**: Use the sidebar to upload your PDF, TXT, or DOCX files
3. **Process Documents**: Click "Process Documents" to index your files
4. **Start Chatting**: Ask questions about your documents in the chat interface

### ğŸ›ï¸ **Sidebar Controls**
- **ğŸ¨ Theme Toggle**: Switch between light and dark modes
- **ğŸ“ Document Upload**: Drag and drop or browse for files
- **ğŸ”§ System Status**: Monitor Qdrant and Ollama services
- **ğŸ—‘ï¸ Clear Chat**: Reset conversation history
- **ğŸ’¡ Tips**: Helpful guidance for better results

### ğŸ’¡ **Pro Tips**
- **Upload Multiple Documents**: Combine related files for better context
- **Ask Specific Questions**: Detailed questions get better answers
- **Use Natural Language**: Chat as you would with a human assistant
- **Check Sources**: Review which documents were used for answers

---

## ğŸ—ï¸ Technical Architecture

### **Frontend**
- **Streamlit**: Modern, responsive web interface
- **Custom CSS**: Beautiful gradients and animations
- **Theme System**: Dynamic light/dark mode switching
- **Real-time Updates**: Live status monitoring

### **Backend**
- **Document Processing**: Intelligent chunking and embedding
- **Vector Search**: Fast similarity search with Qdrant
- **LLM Integration**: Flexible model support via Ollama
- **Session Management**: Persistent chat history

### **Data Flow**
```
Documents â†’ Chunking â†’ Embedding â†’ Vector Store â†’ Query â†’ Retrieval â†’ LLM â†’ Response
```

---

## ğŸ› ï¸ Technology Stack

| Component | Technology | Purpose |
|-----------|------------|---------|
| **UI Framework** | Streamlit | Web interface and user experience |
| **Vector Database** | Qdrant | Fast similarity search and storage |
| **LLM Server** | Ollama | Local model serving and inference |
| **Embedding Model** | BGE-Small-EN | Document and query vectorization |
| **Document Processing** | PyPDF, python-docx | PDF and DOCX file parsing |
| **Chunking** | Custom Algorithm | Intelligent document segmentation |

---

## ğŸ“ Project Structure

```
RAG-Chat-Assistant/
â”œâ”€â”€ ğŸ“„ app.py                 # Main Streamlit application
â”œâ”€â”€ âš™ï¸ config.py              # Configuration settings
â”œâ”€â”€ ğŸ“‹ requirements.txt       # Python dependencies
â”œâ”€â”€ ğŸš€ setup.sh               # Automated setup script
â”œâ”€â”€ ğŸ“š ingest/                # Document processing
â”‚   â”œâ”€â”€ document_loader.py    # File loading utilities
â”‚   â””â”€â”€ chunker.py           # Text chunking algorithm
â”œâ”€â”€ ğŸ” retrieval/             # Vector search
â”‚   â”œâ”€â”€ embedder.py          # Embedding generation
â”‚   â””â”€â”€ vectorstore.py       # Qdrant integration
â”œâ”€â”€ ğŸ§  generation/            # LLM integration
â”‚   â””â”€â”€ llm_wrapper.py       # Ollama communication
â”œâ”€â”€ ğŸ› ï¸ utils/                 # Utilities
â”‚   â”œâ”€â”€ logger.py            # Logging system
â”‚   â””â”€â”€ timer.py             # Performance monitoring
â”œâ”€â”€ ğŸ“ data/                  # User documents
â”œâ”€â”€ ğŸ“Š docs_index/            # Vector database storage
â”œâ”€â”€ ğŸ¤– models/                # Local model files
â””â”€â”€ ğŸ“– README.md              # This documentation
```

---

## ğŸ¯ Use Cases

### ğŸ“š **Academic Research**
- Analyze research papers and academic documents
- Extract key insights from large document collections
- Generate summaries and answer specific questions

### ğŸ’¼ **Business Intelligence**
- Process company reports and documentation
- Extract insights from business documents
- Answer questions about organizational knowledge

### ğŸ“– **Personal Knowledge Management**
- Organize and query personal documents
- Create a searchable knowledge base
- Get instant answers from your document library

### ğŸ“ **Educational Support**
- Study assistance from course materials
- Quick reference for textbooks and notes
- Interactive learning from educational content

---

## ğŸ”§ Configuration

### **Environment Variables**
```bash
# Optional: Set custom ports
export QDRANT_PORT=6333
export OLLAMA_PORT=11434
export STREAMLIT_PORT=8501
```

### **Model Selection**
```bash
# Pull different models for Ollama
ollama pull mistral      # Fast, good quality
ollama pull phi3         # Lightweight, efficient
ollama pull llama3       # High quality, larger
ollama pull codellama    # Code-focused responses
```

---

## ğŸš€ Performance Tips

### **Optimization**
- **RAM**: 16GB+ recommended for smooth operation
- **Storage**: SSD preferred for faster document processing
- **CPU**: Multi-core processor for parallel processing
- **GPU**: Optional for faster embedding generation

### **Scaling**
- **Large Documents**: Process in batches for better performance
- **Multiple Users**: Consider separate instances for heavy usage
- **Document Updates**: Re-process documents when they change

---

## ğŸ› Troubleshooting

### **Common Issues**

| Issue | Solution |
|-------|----------|
| **Qdrant not accessible** | Check Docker is running: `docker ps` |
| **Ollama connection failed** | Verify Ollama is running: `ollama list` |
| **Document upload fails** | Check file format (PDF, TXT, DOCX only) |
| **Slow responses** | Consider using a faster model or more RAM |
| **Theme not switching** | Refresh the browser page |

### **Logs & Debugging**
```bash
# Check Streamlit logs
streamlit run app.py --logger.level debug

# Monitor Qdrant
docker logs qdrant_rag

# Check Ollama status
ollama list
```

---

## ğŸ¤ Contributing

We welcome contributions! Here's how you can help:

1. **Fork** the repository
2. **Create** a feature branch
3. **Make** your changes
4. **Test** thoroughly
5. **Submit** a pull request

### **Development Setup**
```bash
# Install development dependencies
pip install -r requirements-dev.txt

# Run tests
python -m pytest tests/

# Format code
black .
isort .
```

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Qdrant Team** for the excellent vector database
- **Ollama Community** for making local LLMs accessible
- **Streamlit Team** for the amazing web framework
- **Hugging Face** for the BGE embedding models
- **Open Source Community** for all the amazing tools

---

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/Doni1905/RAP-Document_Chatbot/issues)
- **Discussions**: [GitHub Discussions](https://github.com/Doni1905/RAP-Document_Chatbot/discussions)
- **Documentation**: [Wiki](https://github.com/Doni1905/RAP-Document_Chatbot/wiki)

---

**Made with â¤ï¸ using open-source tools**
